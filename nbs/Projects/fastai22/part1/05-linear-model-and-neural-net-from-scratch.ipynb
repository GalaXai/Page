{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "date: 2023-03-17\n",
    "categories: [fastai, DeepLearning]\n",
    "title: p1-05 Linear model and Neural Net from scratch\n",
    "description: Creating a linear model and Neural Net just with pytorch.tensors\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're going to build and train a deep learning model \"from scratch\" -- by which I mean that we're not going to use any pre-built architecture, or optimizers, or data loading frameworks, etc.\n",
    "\n",
    "We'll be assuming you already know the basics of how a neural network works. If you don't, read this notebook first: [How does a neural net really work?\n",
    "](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work). We'll be using Kaggle's [Titanic](https://www.kaggle.com/competitions/titanic/) competition in this notebook, because it's very small and simple, but also has displays many of the tricky real-life issues that we need to handle in most practical projects. (Note, however, that this competition is a small \"learner\" competition on Kaggle, so don't expect to actually see much benefits from using a neural net just yet; that will come once we try our some real competitions!)\n",
    "\n",
    "It's great to be able to run the same notebook on your own machine or Colab, as well as Kaggle. To allow for this, we use this code to download the data as needed when not on Kaggle (see [this notebook](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/) for details about this technique):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to /root/Page/nbs/Projects/fastai22/part1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 34.1k/34.1k [00:00<00:00, 1.41MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = Path('titanic')\n",
    "    if not path.exists():\n",
    "        import zipfile,kaggle\n",
    "        kaggle.api.competition_download_cli(str(path))\n",
    "        zipfile.ZipFile(f'{path}.zip').extractall(path)\n",
    "!rm titanic.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data for Kaggle comps always lives in the `../input` folder. The easiest way to get the path is to click the \"K\" button in the top-right of the Kaggle notebook, click on the folder shown there, and click the copy button.\n",
    "\n",
    "We'll be using *numpy* and *pytorch* for array calculations in this notebook, and *pandas* for working with tabular data, so we'll import them and set them to display using a bit more space than they default to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd\n",
    "np.set_printoptions(linewidth=140)\n",
    "torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n",
    "pd.set_option('display.width', 140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n",
       "0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n",
       "1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n",
       "2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n",
       "3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n",
       "4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n",
       "..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n",
       "886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n",
       "887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n",
       "888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n",
       "889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n",
       "890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n",
       "\n",
       "        Fare Cabin Embarked  \n",
       "0     7.2500   NaN        S  \n",
       "1    71.2833   C85        C  \n",
       "2     7.9250   NaN        S  \n",
       "3    53.1000  C123        S  \n",
       "4     8.0500   NaN        S  \n",
       "..       ...   ...      ...  \n",
       "886  13.0000   NaN        S  \n",
       "887  30.0000   B42        S  \n",
       "888  23.4500   NaN        S  \n",
       "889  30.0000  C148        C  \n",
       "890   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if our data has any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see some of `age` and `Cabin` values are missing, we will handle that with filling them in with the `mode` of the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                      1\n",
       "Survived                       0.0\n",
       "Pclass                         3.0\n",
       "Name           Abbing, Mr. Anthony\n",
       "Sex                           male\n",
       "Age                           24.0\n",
       "SibSp                          0.0\n",
       "Parch                          0.0\n",
       "Ticket                        1601\n",
       "Fare                          8.05\n",
       "Cabin                      B96 B98\n",
       "Embarked                         S\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes = df.mode().iloc[0]\n",
    "modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He are the modes for every value \\\n",
    "and we fill in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how our numerical values are distributed with `describe()` method, `include` parameters ensures we only see numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>28.566970</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.199572</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=(np.number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `describe` we can see that `Fare` has `max` value of 512 while the `min` value is 0 and 75% of the Fare's are below 31 lets see Fare distribution on the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Fare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As w can see most of our values are low numbers with some values a lot higher, it is actually common distribution in monetary values. One way to deal with this problem is to take a log of values. \\\n",
    "We will actually take a log(a+1) since log of number lower than 1 is negative number, and we want our numbers to all be non negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LogFare'] = np.log(df['Fare']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['LogFare'].hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our distribution look a lot better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like from the `describe()` output, the Pclass has only `3` values, which we can confirm by looking at `Pclass.unique()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pclasses = sorted(df.Pclass.unique())\n",
    "pclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we get a quick summary of all the non-numeric columns in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>691</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      891      891\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7      691      646"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we can't multiply strings like `Sex` `male` by a parameter, we need to replace them with numbers. \\\n",
    "With `Sex` column it is pretty simple, just replace male with `1` and female with `0`. \\\n",
    "For the other values we will create additional column saying for example `is` this Embarked: `S` if yes just set value to `1` else `0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can create these automatically with `get_dummies` method, which also removes original columns. We'll create dummy variables for `Pclass`, even although it's numeric, since the numbers 1, 2, and 3 correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for `Sex` and `Embarked` since we'll want to use those as predictors in our model. On the other hand, Cabin, Name, and Ticket have too many unique values for it to make sense creating dummy variables for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the added columns look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n",
       "0         1           0         0         0         1           0           0           1\n",
       "1         0           1         1         0         0           1           0           0\n",
       "2         0           1         0         0         1           0           0           1\n",
       "3         0           1         1         0         0           0           0           1\n",
       "4         1           0         0         0         1           0           0           1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "df[added_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create our independent(predictor)and the dependent(target) the value we want our model to predict. We want both of them to be `tensors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "t_dep = tensor(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        ...,\n",
       "        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n",
       "        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n",
       "        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n",
       "        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n",
    "\n",
    "t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n",
    "t_indep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the number of rows and columns we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([891, 12])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a matrix of independent and dependent values, we can work on calculating our predictions and our loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first model will be a simple linear model. We'll need a `coefficient`(Parameter) for each column in `t_indep`. We'll assign it a random number between -0.5 and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(442)\n",
    "\n",
    "n_coeff = t_indep.shape[1]\n",
    "coeffs = torch.rand(n_coeff)-0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created our coeffs [12,1] tensor. \\\n",
    "Here is what the multiplication looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        ...,\n",
       "        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n",
       "        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n",
       "        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n",
       "        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n",
       "        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]),\n",
       "indices=tensor([630, 159, 678, 258,   0,   1,   1,   9,   0,   1,   5,   0]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep.max(dim =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see we've got a problem here. The sum of  each row will be dominated by the `Age` column, since it's bigger on the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make all the columns contain numbers from `0` to `1`, by dividing each column by its `max()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals,indices = t_indep.max(dim=0)\n",
    "t_indep = t_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        ...,\n",
       "        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n",
       "        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n",
       "        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n",
       "        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_indep*coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it look a lot better. \\\n",
    "Now we can make prediction from our linear model, by adding up the rows of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE for axis \n",
    "* if 0 - > return sum of columns \n",
    "* if 1 - > return sum of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = (t_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, those predictions aren't good since our coefficient were random. To do the gradient descent, we need a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = torch.abs(preds-t_dep).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've tested out a way of calculating predictions, and loss, let's pop them into functions to make life easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n",
    "def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing the gradient descent step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try to improve our coefficient by calculating the gradients and updating our coeffs. \\\n",
    "To get pytorch to calculate the gradients, we need to call `required_grad_()` on our `coeffs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5382, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `backward()` to ask PyTorch to calculate gradients now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what they look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each time we will call `bakwards()`. The gradients are actually added to whatever is in the .grad attribute. Let's try running the above steps again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "coeffs.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our `.grad` values have doubled. That's because it added the gradients a second time. \\\n",
    "For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do one gradient descent step, and check that our loss decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4945)\n"
     ]
    }
   ],
   "source": [
    "loss = calc_loss(coeffs, t_indep, t_dep)\n",
    "loss.backward()\n",
    "with torch.no_grad(): # We use .no_grad() here since w don't want gradients of .sub_\n",
    "    coeffs.sub_(coeffs.grad * 0.1)\n",
    "    coeffs.grad.zero_()\n",
    "    print(calc_loss(coeffs, t_indep, t_dep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `abc.sub_(b)` subtracts `b` from the `a` in-place. In PyTorch, any method that ends with `_` changes the object in place. Similar `abc.zero()` sets all the elements of tensor to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import RandomSplitter from fastai and split our data into training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split,val_split=RandomSplitter(seed=42)(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply those indicies to our independent and dependent variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 178)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n",
    "trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n",
    "len(trn_indep),len(val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lest's create a function to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch(coeffs, lr):\n",
    "    loss = calc_loss(coeffs, trn_indep, trn_dep)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"{loss:.3f}\", end=\"; \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder this function will initialize coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these functions to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.01):\n",
    "    torch.manual_seed(442)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model for 18 epochs with lr = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(18, lr=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does!\n",
    "\n",
    "Let's take a look at the coefficients for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-0.2694),\n",
       " 'SibSp': tensor(0.0901),\n",
       " 'Parch': tensor(0.2359),\n",
       " 'LogFare': tensor(0.0280),\n",
       " 'Sex_male': tensor(-0.3990),\n",
       " 'Sex_female': tensor(0.2345),\n",
       " 'Pclass_1': tensor(0.7232),\n",
       " 'Pclass_2': tensor(0.4112),\n",
       " 'Pclass_3': tensor(0.3601),\n",
       " 'Embarked_C': tensor(0.0955),\n",
       " 'Embarked_Q': tensor(0.2395),\n",
       " 'Embarked_S': tensor(0.2122)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n",
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Kaggle competition is not, however, scored by absolute error (which is our loss function). It's scored by *accuracy* -- the proportion of rows where we correctly predict survival. Let's see how accurate we were on the validation set. First, calculate the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = calc_preds(coeffs, val_indep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll assume that any passenger with a score of over `0.5` is predicted to survive. So that means we're correct for each row where `preds>0.5` is the same as the dependent variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = val_dep.bool()==(preds>0.5)\n",
    "results[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what our average accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a bad start at all! We'll create a function so we can calcuate the accuracy easy for other models we train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7865)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.5)).float().mean()\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our predictions,we can see that some of the values are `>1` and some of them are `<0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,\n",
       "         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this we can put our prediction into sigmoid function, which has minimum of 0 and maximum of 1. \\\n",
    "Here is what is looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sympy\n",
    "sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch already defines that function for us, so we just need to modify the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510; 0.327; 0.294; 0.207; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy went up by a lot! Let's the coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': tensor(-1.5061),\n",
       " 'SibSp': tensor(-1.1575),\n",
       " 'Parch': tensor(-0.4267),\n",
       " 'LogFare': tensor(0.2543),\n",
       " 'Sex_male': tensor(-10.3320),\n",
       " 'Sex_female': tensor(8.4185),\n",
       " 'Pclass_1': tensor(3.8389),\n",
       " 'Pclass_2': tensor(2.1398),\n",
       " 'Pclass_3': tensor(-6.2331),\n",
       " 'Embarked_C': tensor(1.4771),\n",
       " 'Embarked_Q': tensor(2.1168),\n",
       " 'Embarked_S': tensor(-4.7958)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_coeffs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've got a trained model, we can prepare a submission to Kaggle. To do that, first we need to read the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df = pd.read_csv(path/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Fare'] = tst_df.Fare.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df.fillna(modes, inplace=True)\n",
    "tst_df['LogFare'] = np.log(tst_df['Fare']+1)\n",
    "tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n",
    "\n",
    "tst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n",
    "tst_indep = tst_indep / vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df['Survived'] = (calc_preds(tst_indep, coeffs)>0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = tst_df[['PassengerId','Survived']]\n",
    "sub_df.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the first few rows of the file to make sure it looks reasonable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId,Survived\n",
      "892,0\n",
      "893,0\n",
      "894,0\n",
      "895,0\n",
      "896,0\n",
      "897,0\n",
      "898,1\n",
      "899,0\n",
      "900,1\n"
     ]
    }
   ],
   "source": [
    "!head sub.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you click \"save version\" in Kaggle, and wait for the notebook to run, you'll see that `sub.csv` appears in the \"Data\" tab. Clicking on that file will show a *Submit* button, which allows you to submit to the competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make things quite a bit neater...\n",
    "\n",
    "Take a look at the inner-most calculation we're doing to get the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3512, -13.6469,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n",
       "          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n",
       "         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n",
       "         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n",
       "        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n",
       "        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n",
       "        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n",
       "        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n",
       "        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n",
       "        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n",
       "          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n",
       "        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n",
       "        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n",
       "        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(val_indep*coeffs).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the `@` operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n",
       "          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n",
       "         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n",
       "         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n",
       "        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n",
       "        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n",
       "        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n",
       "        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n",
       "        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n",
       "        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n",
       "          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n",
       "        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n",
       "        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n",
       "        -12.1838,  -3.0873, -21.6070,   7.0744, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_indep@coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As u can see the output is identical, but using `@` operator makes the matrix multiply much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dep = trn_dep[:,None]\n",
    "val_dep = val_dep[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our model as before and confirm we get identical outputs...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.512; 0.323; 0.290; 0.205; 0.200; 0.198; 0.197; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and identical accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got what we need to implement our neural network.\n",
    "\n",
    "First, we'll need to create coefficients for each of our layers. Our first set of coefficients will take our `n_coeff` inputs, and create `n_hidden` outputs. We can choose whatever `n_hidden` we like -- a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size `n_coeff` by `n_hidden`. We'll divide these coefficients by `n_hidden` so that when we sum them up in the next layer we'll end up with similar magnitude numbers to what we started with.\n",
    "\n",
    "Then our second layer will need to take the `n_hidden` inputs and create a single output, so that means we need a `n_hidden` by `1` matrix there. The second layer will also need a constant term added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7839, 0.4441, 0.7304, 0.4664, 0.4205, 0.9709, 0.0276, 0.5295, 0.7127, 0.7399, 0.9193, 0.9949, 0.9180, 0.6263, 0.3220, 0.2740,\n",
       "        0.9050, 0.5448, 0.1600, 0.1784])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 20\n",
    "(torch.rand(n_coeff, n_hidden)) # n_coeffs - number of rows, n_hidden - number of coeffs in a row\n",
    "torch.rand(n_hidden,1) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs(n_hidden=20):\n",
    "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
    "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
    "    const = torch.rand(1)[0]\n",
    "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, `indeps@l1` and `res@l2` (where `res` is the output of the first layer). The first layer output is passed to `F.relu` (that's our non-linearity), and the second is passed to `torch.sigmoid` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    l1,l2,const = coeffs\n",
    "    res = F.relu(indeps@l1)\n",
    "    res = res@l2 + const\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, now that we have more than one set of coefficients, we need to add a loop to update each one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it -- we're now ready to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.532; 0.520; 0.505; 0.487; 0.466; 0.439; 0.407; 0.373; 0.343; 0.319; 0.301; 0.286; 0.274; 0.264; 0.256; 0.250; 0.245; 0.240; 0.237; 0.234; 0.231; 0.229; 0.227; 0.226; 0.224; 0.223; 0.222; 0.221; 0.220; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.7921)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = train_model(lr=1.4)\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543; 0.400; 0.260; 0.390; 0.221; 0.211; 0.197; 0.195; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.193; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; 0.192; "
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs = train_model(lr=20)\n",
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case our neural net isn't showing better results than the linear model. That's not surprising; this dataset is very small and very simple, and isn't the kind of thing we'd expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net in the previous section only uses one hidden layer, so it doesn't count as \"deep\" learning. But we can use the exact same technique to make our neural net deep, by adding more matrix multiplications.\n",
    "\n",
    "First, we'll need to create additional coefficients for each layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding `init_coeffs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 10, 10, 1]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [12] + [10,10] + [1]\n",
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0885, -0.0638,  0.0772, -0.0345,  0.0909,  0.1749,  0.0677,  0.0966,  0.1951,  0.2063],\n",
       "         [-0.0830,  0.1576,  0.0236, -0.0339, -0.0435,  0.1856,  0.0527, -0.0925,  0.2777,  0.2286],\n",
       "         [ 0.2143,  0.2019, -0.1154, -0.1139,  0.1705,  0.1669,  0.0929,  0.0492,  0.0093,  0.0219],\n",
       "         [ 0.2064,  0.0697,  0.1346,  0.0099,  0.0619,  0.1576,  0.1706,  0.2313,  0.1813,  0.1084],\n",
       "         [-0.0234,  0.1411,  0.1117,  0.2572,  0.1412,  0.0425, -0.0518,  0.2002,  0.2679,  0.1291],\n",
       "         [ 0.0778, -0.0274, -0.0914,  0.0320,  0.0827,  0.2084, -0.0432, -0.0596, -0.1159,  0.1561],\n",
       "         [-0.0663,  0.0115, -0.0512, -0.0736,  0.1799, -0.1023,  0.2382,  0.1505, -0.1048, -0.1080],\n",
       "         [ 0.0528,  0.1592,  0.1679,  0.1505,  0.2484, -0.0191, -0.0484,  0.1934,  0.1189,  0.0669],\n",
       "         [ 0.1171,  0.2428,  0.2765, -0.1061,  0.1507,  0.1123,  0.0138,  0.2528, -0.0910,  0.2024],\n",
       "         [-0.0933,  0.2470,  0.0178, -0.0918,  0.0222, -0.0396,  0.1512,  0.2310,  0.0195,  0.1205],\n",
       "         [ 0.1871,  0.2252, -0.1103, -0.1024,  0.0265, -0.0765,  0.1559,  0.0525,  0.0626,  0.2296],\n",
       "         [-0.0404,  0.0415, -0.0964,  0.1770,  0.2407, -0.0885,  0.1886,  0.0988,  0.1241, -0.0197]]),\n",
       " tensor([[ 0.2503,  0.1817,  0.0126,  0.2533,  0.1894,  0.0409,  0.0346,  0.1906,  0.0028, -0.0500],\n",
       "         [ 0.2727,  0.1456, -0.0822,  0.2615,  0.1846, -0.0088, -0.0702,  0.0786,  0.0612,  0.0029],\n",
       "         [-0.0630,  0.1806,  0.0933,  0.0588,  0.1733,  0.1716,  0.2244, -0.0117,  0.2667,  0.1549],\n",
       "         [ 0.1669, -0.0602, -0.0441,  0.1185, -0.0435, -0.0968,  0.0763, -0.0793,  0.1789,  0.2125],\n",
       "         [-0.0753,  0.2657,  0.1949,  0.1723, -0.0889,  0.0771,  0.1567,  0.1438,  0.1492, -0.0557],\n",
       "         [-0.0700, -0.0379,  0.1252,  0.1553,  0.2358,  0.1180,  0.1481, -0.0947, -0.0519, -0.0530],\n",
       "         [-0.0951,  0.1704,  0.1018,  0.0124, -0.0813,  0.1127,  0.0923,  0.2073,  0.1874, -0.0929],\n",
       "         [ 0.0547,  0.0722,  0.1718, -0.0851, -0.0137,  0.2170,  0.2518,  0.0099, -0.0562, -0.0901],\n",
       "         [-0.0364,  0.1456,  0.0073, -0.0689, -0.0381,  0.0609,  0.1470,  0.1278,  0.1969,  0.2251],\n",
       "         [ 0.2415, -0.0258,  0.2668,  0.2486, -0.1069,  0.1885,  0.0146,  0.1928,  0.0357,  0.0407]]),\n",
       " tensor([[ 0.1598],\n",
       "         [ 1.9081],\n",
       "         [ 1.9844],\n",
       "         [ 2.6781],\n",
       "         [ 1.3237],\n",
       "         [ 1.2417],\n",
       "         [ 2.5576],\n",
       "         [ 0.4801],\n",
       "         [-0.8827],\n",
       "         [ 2.3167]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(sizes)\n",
    "ly = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0139), tensor(-0.0015), tensor(-0.0319)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0885, -0.0638,  0.0772, -0.0345,  0.0909,  0.1749,  0.0677,  0.0966,  0.1951,  0.2063],\n",
      "        [-0.0830,  0.1576,  0.0236, -0.0339, -0.0435,  0.1856,  0.0527, -0.0925,  0.2777,  0.2286],\n",
      "        [ 0.2143,  0.2019, -0.1154, -0.1139,  0.1705,  0.1669,  0.0929,  0.0492,  0.0093,  0.0219],\n",
      "        [ 0.2064,  0.0697,  0.1346,  0.0099,  0.0619,  0.1576,  0.1706,  0.2313,  0.1813,  0.1084],\n",
      "        [-0.0234,  0.1411,  0.1117,  0.2572,  0.1412,  0.0425, -0.0518,  0.2002,  0.2679,  0.1291],\n",
      "        [ 0.0778, -0.0274, -0.0914,  0.0320,  0.0827,  0.2084, -0.0432, -0.0596, -0.1159,  0.1561],\n",
      "        [-0.0663,  0.0115, -0.0512, -0.0736,  0.1799, -0.1023,  0.2382,  0.1505, -0.1048, -0.1080],\n",
      "        [ 0.0528,  0.1592,  0.1679,  0.1505,  0.2484, -0.0191, -0.0484,  0.1934,  0.1189,  0.0669],\n",
      "        [ 0.1171,  0.2428,  0.2765, -0.1061,  0.1507,  0.1123,  0.0138,  0.2528, -0.0910,  0.2024],\n",
      "        [-0.0933,  0.2470,  0.0178, -0.0918,  0.0222, -0.0396,  0.1512,  0.2310,  0.0195,  0.1205],\n",
      "        [ 0.1871,  0.2252, -0.1103, -0.1024,  0.0265, -0.0765,  0.1559,  0.0525,  0.0626,  0.2296],\n",
      "        [-0.0404,  0.0415, -0.0964,  0.1770,  0.2407, -0.0885,  0.1886,  0.0988,  0.1241, -0.0197]])\n",
      "tensor([[ 0.2503,  0.1817,  0.0126,  0.2533,  0.1894,  0.0409,  0.0346,  0.1906,  0.0028, -0.0500],\n",
      "        [ 0.2727,  0.1456, -0.0822,  0.2615,  0.1846, -0.0088, -0.0702,  0.0786,  0.0612,  0.0029],\n",
      "        [-0.0630,  0.1806,  0.0933,  0.0588,  0.1733,  0.1716,  0.2244, -0.0117,  0.2667,  0.1549],\n",
      "        [ 0.1669, -0.0602, -0.0441,  0.1185, -0.0435, -0.0968,  0.0763, -0.0793,  0.1789,  0.2125],\n",
      "        [-0.0753,  0.2657,  0.1949,  0.1723, -0.0889,  0.0771,  0.1567,  0.1438,  0.1492, -0.0557],\n",
      "        [-0.0700, -0.0379,  0.1252,  0.1553,  0.2358,  0.1180,  0.1481, -0.0947, -0.0519, -0.0530],\n",
      "        [-0.0951,  0.1704,  0.1018,  0.0124, -0.0813,  0.1127,  0.0923,  0.2073,  0.1874, -0.0929],\n",
      "        [ 0.0547,  0.0722,  0.1718, -0.0851, -0.0137,  0.2170,  0.2518,  0.0099, -0.0562, -0.0901],\n",
      "        [-0.0364,  0.1456,  0.0073, -0.0689, -0.0381,  0.0609,  0.1470,  0.1278,  0.1969,  0.2251],\n",
      "        [ 0.2415, -0.0258,  0.2668,  0.2486, -0.1069,  0.1885,  0.0146,  0.1928,  0.0357,  0.0407]])\n",
      "tensor([[ 0.1598],\n",
      "        [ 1.9081],\n",
      "        [ 1.9844],\n",
      "        [ 2.6781],\n",
      "        [ 1.3237],\n",
      "        [ 1.2417],\n",
      "        [ 2.5576],\n",
      "        [ 0.4801],\n",
      "        [-0.8827],\n",
      "        [ 2.3167]])\n",
      "tensor(0.0139)\n",
      "tensor(-0.0015)\n",
      "tensor(-0.0319)\n"
     ]
    }
   ],
   "source": [
    "for i in ly + con:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coeffs():\n",
    "    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n",
    "    sizes = [n_coeff] + hiddens + [1]\n",
    "    n = len(sizes)\n",
    "    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n",
    "    # Creates n-1 number of layers\n",
    "    # First layer [n_coeffs,hidden] second layer [hidden,hidden], third [hidden,1]\n",
    "    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n",
    "    # Create (n-1) number of constants for each layer\n",
    "    for l in layers+consts: l.requires_grad_()\n",
    "    # adds requires grad to each layer and const \n",
    "    return layers,consts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days -- it's very finicky to get a good starting point for our coefficients. Nowadays, we have ways to deal with that, which we'll learn about in other notebooks.\n",
    "\n",
    "Our deep learning `calc_preds` looks much the same as before, but now we loop through each layer, instead of listing them separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def calc_preds(coeffs, indeps):\n",
    "    layers,consts = coeffs\n",
    "    n = len(layers)\n",
    "    res = indeps\n",
    "    for i,l in enumerate(layers):\n",
    "        # This does the same thing neural network does\n",
    "        # res * l_n + consts\n",
    "        # loops -> n+1\n",
    "        res = res@l + consts[i]\n",
    "        if i!=n-1: res = F.relu(res) # Updates res\n",
    "    return torch.sigmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a minor update to `update_coeffs` since we've got `layers` and `consts` separated now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old ones for the comparason\n",
    "```Python\n",
    "def update_coeffs(coeffs, lr):\n",
    "    for layer in coeffs:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_coeffs(coeffs, lr):\n",
    "    layers,consts = coeffs\n",
    "    for layer in layers+consts:\n",
    "        layer.sub_(layer.grad * lr)\n",
    "        layer.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.521; 0.483; 0.427; 0.379; 0.379; 0.379; 0.379; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.378; 0.377; 0.376; 0.371; 0.333; 0.239; 0.224; 0.208; 0.204; 0.203; 0.203; 0.207; 0.197; 0.196; 0.195; "
     ]
    }
   ],
   "source": [
    "coeffs = train_model(lr=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and check its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8258)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's actually pretty cool that we've managed to create a real deep learning model from scratch and trained it to get over 80% accuracy on this task, all in the course of a single notebook!\n",
    "\n",
    "The \"real\" deep learning models that are used in research and industry look very similar to this, and in fact if you look inside the source code of any deep learning model you'll recognise the basic steps are the same.\n",
    "\n",
    "The biggest differences in practical models to what we have above are:\n",
    "\n",
    "- How initialisation and normalisation is done to ensure the model trains correctly every time\n",
    "- Regularization (to avoid over-fitting)\n",
    "- Modifying the neural net itself to take advantage of knowledge of the problem domain\n",
    "- Doing gradient descent steps on smaller batches, rather than the whole dataset.\n",
    "\n",
    "I'll be adding notebooks about all these later, and will add links here once they're ready.\n",
    "\n",
    "If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you're looking at my [original notebook here](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) when you do that, and are not on your own copy of it, otherwise your upvote won't get counted!) And if you have any questions or comments, please pop them below -- I read every comment I receive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "!rm -r titanic\n",
    "!rm sub.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
